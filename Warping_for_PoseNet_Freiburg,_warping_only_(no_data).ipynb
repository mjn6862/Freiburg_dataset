{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Warping for PoseNet - Freiburg, warping only (no data)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjn6862/Freiburg_dataset/blob/master/Warping_for_PoseNet_Freiburg%2C_warping_only_(no_data).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kq-rlJxzHbr",
        "colab_type": "text"
      },
      "source": [
        "**Import Statements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypG-_b90k7Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow_graphics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sguc70jY5xt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_graphics.geometry.transformation as tfg_transformation\n",
        "from tensorflow import keras\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "from datetime import datetime\n",
        "import csv\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D0xuO74GB9N",
        "colab_type": "text"
      },
      "source": [
        "**Define the input layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAQDTSVmxI7p",
        "colab_type": "text"
      },
      "source": [
        "**Create HTM from 6x1**\n",
        "\n",
        "Equations taken from DVO paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfgLVnl4GHC1",
        "colab_type": "text"
      },
      "source": [
        "**Define the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BszGQ-CEGEDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = tf.keras.layers.Input(shape=(480, 640, 3), name=\"first_image\")\n",
        "depth_A = tf.keras.layers.Input(shape=(480, 640, 1), name=\"first_depth\")\n",
        "input_B = tf.keras.layers.Input(shape=(480, 640, 3), name=\"second_image\")\n",
        "depth_B = tf.keras.layers.Input(shape=(480, 640, 1), name=\"second_depth\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2emlkaGmHuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_dim = 6\n",
        "concat = tf.keras.layers.concatenate([input_A, input_B])\n",
        "conv1 = tf.keras.layers.Conv2D(16,(7, 7), padding='same', strides=(2, 2), activation='relu')(concat)\n",
        "conv2 = tf.keras.layers.Conv2D(32, (5, 5), padding='same', strides=(2, 2), activation='relu')(conv1)\n",
        "conv3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv2)\n",
        "conv4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv3)\n",
        "conv5 = tf.keras.layers.Conv2D(256,(3, 3), padding='same', strides=(2, 2), activation='relu')(conv4)\n",
        "conv6 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv5)\n",
        "conv7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv6)\n",
        "readout = tf.keras.layers.Conv2D(out_dim, (1, 1))(conv7)\n",
        "readout = 0.1*tf.keras.layers.AveragePooling2D((4,5))(readout)\n",
        "readout = tf.keras.layers.Flatten()(readout)       # first three elements correspond to the rotational velocity and the other three to the traslational velocity\n",
        "#htm = batch_mat_exp(readout)\n",
        "#image_A = tf.keras.backend.reshape(input_A,(1,480,640,3))\n",
        "#out_img = warp_image(image_A, depth_A, htm)\n",
        "#model = tf.keras.models.Model(inputs=[input_A, depth_A, input_B, depth_B], outputs=[htm])\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL-DAJ49RWwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hx, wx, h1 as the homogeneous pixel coordinates\n",
        "# This appears to match the original paper's output format\n",
        "height_coord = range(480)\n",
        "width_coord = range(640)\n",
        "hx, wx = pixel_coord = np.meshgrid(height_coord, width_coord, indexing='ij')\n",
        "hx = hx.reshape((480, 640, 1))\n",
        "wx = wx.reshape((480, 640, 1))\n",
        "h1 = np.ones(hx.shape)\n",
        "\n",
        "grid = np.concatenate((hx, wx, h1), axis=-1)\n",
        "\n",
        "# Define the camera intrinsic matrix\n",
        "#K = np.array([[525.,0.,319.5], [0., 525., 239.5], [0.,0.,1.]])  # This is how the rostopic defines it\n",
        "K = np.array([[525.,0.,239.5], [0., 525., 319.5], [0.,0.,1.]])\n",
        "\n",
        "# Define the camera coordinates of each piel up to a depth scale factor\n",
        "unscaled_cam_coord = np.empty(grid.shape)\n",
        "for i in range(480):\n",
        "      for j in range(640):\n",
        "        unscaled_cam_coord[i,j,:]= np.linalg.inv(K).dot(grid[i,j,:])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxoaCbCJO5n9",
        "colab_type": "text"
      },
      "source": [
        "**Starting here: layers to go from 6-dim vector to 4x4 HTM within model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY5fR8urnHCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_xi = tf.keras.layers.Input(shape=(6), name=\"xi\")\n",
        "input_pose = tf.keras.layers.Flatten()(input_xi) # just a layer that will make things easier to connect later; replace input_xi with readout to connect to bigger model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNB8EBR38Vuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 3x3 matrix omega_x from xi=[omega nu]\n",
        "omega_x_weights = np.zeros([6,9])\n",
        "omega_x_weights[0,5]=-1\n",
        "omega_x_weights[0,7]=1\n",
        "omega_x_weights[1,2]=1\n",
        "omega_x_weights[1,6]=-1\n",
        "omega_x_weights[2,1]=-1\n",
        "omega_x_weights[2,3]=1\n",
        "\n",
        "omega_x = tf.keras.layers.Dense(9,use_bias=False,weights=[omega_x_weights],trainable=False)(input_pose)\n",
        "omega_x = tf.keras.layers.Reshape((3,3))(omega_x)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBtHpM4p9lUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 3-dimensional vector nu from xi=[omega nu]\n",
        "nu_weights = np.zeros([6,3])\n",
        "nu_weights[3,0]=1\n",
        "nu_weights[4,1]=1\n",
        "nu_weights[5,2]=1\n",
        "\n",
        "nu = tf.keras.layers.Dense(3,use_bias=False,weights=[nu_weights],trainable=False)(input_pose)\n",
        "#nu = tf.keras.layers.Reshape((3,1))(nu)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvTvMfTe-UVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get ||omega|| from xi\n",
        "def om_norm_fun(xi):\n",
        "  return tf.norm(xi[0,0:3])\n",
        "om_norm = tf.keras.layers.Lambda(om_norm_fun)(input_pose)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noJLF97wFBqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get omega_x**2\n",
        "omega_x_squared = tf.keras.layers.Dot(axes=(1,2))([omega_x,omega_x])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAE4gzHl_7Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get terms for exp(omega_x) and V\n",
        "# exp(omega_x) = I + term1 + term2 in (2.21)\n",
        "def term1_fun(x):\n",
        "  return tf.sin(x[1])/tf.math.maximum(x[1],1e-16)*x[0] #tf.math.maximum to avoid dividing by 0\n",
        "term1 = tf.keras.layers.Lambda(term1_fun)((omega_x,om_norm))\n",
        "\n",
        "def term2_fun(x):\n",
        "  return (1-tf.cos(x[1]))/tf.math.maximum(x[1],1e-16)**2*x[0] #tf.math.maximum to avoid dividing by 0\n",
        "term2 = tf.keras.layers.Lambda(term2_fun)((omega_x_squared,om_norm))\n",
        "\n",
        "# V = I + term3 + term4 in (2.22)\n",
        "def term3_fun(x):\n",
        "  return (1-tf.cos(x[1]))/tf.math.maximum(x[1],1e-16)**2*x[0] #tf.math.maximum to avoid dividing by 0\n",
        "term3 = tf.keras.layers.Lambda(term3_fun)((omega_x,om_norm))\n",
        "\n",
        "def term4_fun(x):\n",
        "  return (x[1]-tf.sin(x[1]))/tf.math.maximum(x[1],1e-16)**3*x[0] #tf.math.maximum to avoid dividing by 0\n",
        "term4 = tf.keras.layers.Lambda(term4_fun)((omega_x_squared,om_norm))"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJgxKz2TF2rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get exp(omega_x)\n",
        "# exp_om_x = I + term1 + term2\n",
        "exp_om_x = tf.keras.layers.add([term1,term2])\n",
        "# still need to add I.  There might be a more elegant way, but I'm going to do \n",
        "# this by using a Dense layer and specifying the weights\n",
        "exp_om_x = tf.keras.layers.Flatten()(exp_om_x)\n",
        "# use identity for weights to keep the same, then use np.array([1,0,0,0,1,0,0,0,1]) to add identity matrix to exp_om_x\n",
        "exp_om_x = tf.keras.layers.Dense(9,weights=[np.eye(9),np.array([1,0,0,0,1,0,0,0,1])],trainable=False)(exp_om_x)\n",
        "exp_om_x = tf.keras.layers.Reshape((3,3))(exp_om_x)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEaKoGxhJEwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get V and V*nu\n",
        "# V = I + term3 + term4\n",
        "V = tf.keras.layers.add([term3,term4])\n",
        "# still need to add I.  There might be a more elegant way, but I'm going to do \n",
        "# this by using a Dense layer and specifying the weights\n",
        "V = tf.keras.layers.Flatten()(V)\n",
        "# use identity for weights to keep the same, then use np.array([1,0,0,0,1,0,0,0,1]) to add identity matrix to exp_om_x\n",
        "V = tf.keras.layers.Dense(9,weights=[np.eye(9),np.array([1,0,0,0,1,0,0,0,1])],trainable=False)(V) \n",
        "V = tf.keras.layers.Reshape((3,3))(V)\n",
        "# get V*nu\n",
        "V_nu = tf.keras.layers.Dot(axes=(2,1))([V,nu])\n",
        "V_nu = tf.keras.layers.Reshape((3,1))(V_nu)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p79xUmZ7MsXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get exp_xi by concatenating exp_om_x and V_nu, then concatenate a bottom row of [0,0,0,1]\n",
        "exp_xi = tf.keras.layers.concatenate([exp_om_x,V_nu])\n",
        "# this is a silly way to get a bottom row of [0,0,0,1], but it works\n",
        "bottom_row = tf.keras.layers.Dense(4,weights=[np.zeros([6,4]),np.array([0,0,0,1])],trainable=False)(input_pose)\n",
        "bottom_row = tf.keras.layers.Reshape((1,4))(bottom_row)\n",
        "\n",
        "exp_xi = tf.keras.layers.concatenate([exp_xi,bottom_row],axis=1)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG79qnjH8qm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e93831a9-d626-4ca8-af0b-a10fedfd4a73"
      },
      "source": [
        "#w = tf.constant([np.random.rand(480,640,3),np.random.rand(480,640,3)])\n",
        "#x = tf.constant([np.random.rand(480,640,1),np.random.rand(480,640,1)])\n",
        "#y = tf.constant([np.random.rand(480,640,3),np.random.rand(480,640,3)])\n",
        "#z = tf.constant([np.random.rand(480,640,1),np.random.rand(480,640,1)])\n",
        "#model = tf.keras.models.Model(inputs=[input_A,depth_A,input_B,depth_B],outputs=[exp_xi])\n",
        "#model.predict([w,x,y,z])\n",
        "#xi = tf.constant([[0.3,0.2,0.6,0.8,0.5,0.7]])\n",
        "xi = tf.constant([[0.1,0,0,1,2,3]])\n",
        "#xi = tf.constant(np.random.rand(3,6))\n",
        "model = tf.keras.models.Model(inputs=[input_xi],outputs=[exp_xi])\n",
        "model.predict(xi)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 1.        ,  0.        ,  0.        ,  1.        ],\n",
              "        [ 0.        ,  0.99500417, -0.09983342,  1.84679329],\n",
              "        [ 0.        ,  0.09983342,  0.99500417,  3.0949192 ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  1.        ]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27JWhZNvQeQG",
        "colab_type": "text"
      },
      "source": [
        "**Here starts the attempts to warp from input_A, depth_A, and exp_xi**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBBK7_IrQdEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hx, wx, h1 as the homogeneous pixel coordinates\n",
        "# This appears to match the original paper's output format\n",
        "height_coord = range(480)\n",
        "width_coord = range(640)\n",
        "hx, wx = pixel_coord = np.meshgrid(height_coord, width_coord, indexing='ij')\n",
        "hx = hx.reshape((480, 640, 1))\n",
        "wx = wx.reshape((480, 640, 1))\n",
        "h1 = np.ones(hx.shape)\n",
        "\n",
        "grid = np.concatenate((hx, wx, h1), axis=-1)\n",
        "\n",
        "# Define the camera intrinsic matrix\n",
        "#K = np.array([[525.,0.,319.5], [0., 525., 239.5], [0.,0.,1.]])  # This is how the rostopic defines it\n",
        "K = np.array([[525.,0.,239.5], [0., 525., 319.5], [0.,0.,1.]])\n",
        "\n",
        "# Define the camera coordinates of each piel up to a depth scale factor\n",
        "unscaled_cam_coord = np.empty(grid.shape)\n",
        "for i in range(480):\n",
        "      for j in range(640):\n",
        "        unscaled_cam_coord[i,j,:]= np.linalg.inv(K).dot(grid[i,j,:])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH3wr94Piyem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def warp_image(tensor):\n",
        "  image1 = tensor[0]\n",
        "  depth1 = tensor[1]\n",
        "  delta_pose = tensor[2]\n",
        "  # This function takes an image and depth map and predicts the view after a transformation by delta_pose\n",
        "  # What would image1 taken at the location after delta_pose look like? Should match image2\n",
        "  new_image = tf.keras.backend.ones_like(image1)\n",
        "  camera_coord = tf.reshape(depth1[-1,:,:],(307200,1))*unscaled_cam_coord.reshape(307200, 3)\n",
        "  homog_camera_coord = tf.keras.backend.concatenate((camera_coord, tf.keras.backend.ones((307200,1),dtype=tf.float64)) )\n",
        "  pixel_list = tf.keras.backend.zeros((307200, 2))\n",
        "  new_homog_camera_coord = tf.keras.backend.dot(homog_camera_coord, tf.keras.backend.transpose(tf.reshape(delta_pose,(4,4))))\n",
        "  new_homog_camera_coord = tf.math.divide(new_homog_camera_coord, tf.reshape(new_homog_camera_coord[:,2], (307200,1)) ) \n",
        "  #print('new_homog_camera_coord=',new_homog_camera_coord)\n",
        "  pixel_list = tf.keras.backend.dot(tf.reshape(new_homog_camera_coord[:,0:3],(307200,3)), tf.keras.backend.transpose(K))\n",
        "  #print('pixel_list=',pixel_list)\n",
        "  print(tf.reshape(image1[-1, :, :, :], (1, 480, 640,3)))\n",
        "  print(tf.reshape(pixel_list[:,0:2], (-1,307200,2)))\n",
        "  interp = tfa.image.interpolate_bilinear(grid=tf.reshape(image1[-1, :, :, :], (1, 480, 640,3)), query_points=tf.reshape(pixel_list[:,0:2], (-1,307200,2)))\n",
        "  #print('interp=',interp)\n",
        "  new_image = tf.reshape(interp, (-1,480, 640, 3))\n",
        "  #print('new_image=',new_image)\n",
        "  #print('camer_coord=',camera_coord)\n",
        "  #print('homog_camera_coord=',homog_camera_coord)\n",
        "  #print('pixel_list=',pixel_list)\n",
        "  #print('new_homog_camera_coord=',new_homog_camera_coord)\n",
        "  #print('interp=',interp)\n",
        "  #print('new_image=',new_image)\n",
        "  return new_image#, camera_coord, homog_camera_coord, new_homog_camera_coord, pixel_list, interp"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2VvCuyNkkDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "cd842798-12b7-4d3a-b5ea-00547f33533f"
      },
      "source": [
        "out = tf.keras.layers.Lambda(warp_image, name='warp_layer')([input_A, depth_A, exp_xi])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"warp_layer/Reshape_4:0\", shape=(1, 480, 640, 3), dtype=float64)\n",
            "Tensor(\"warp_layer/Reshape_5:0\", shape=(1, 307200, 2), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-1a7a4bbc54c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warp_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_xi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    921\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_check_variables\u001b[0;34m(self, created_variables, accessed_variables)\u001b[0m\n\u001b[1;32m    914\u001b[0m           Variables.'''\n\u001b[1;32m    915\u001b[0m       ).format(name=self.name, variable_str=variable_str)\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     untracked_used_vars = [\n",
            "\u001b[0;31mValueError\u001b[0m: \nThe following Variables were created within a Lambda layer (warp_layer)\nbut are not tracked by said layer:\n  <tf.Variable 'warp_layer/Variable:0' shape=(307200, 1) dtype=float64>\n  <tf.Variable 'warp_layer/Variable:0' shape=(307200, 2) dtype=float64>\nThe layer cannot safely ensure proper Variable reuse across multiple\ncalls, and consquently this behavior is disallowed for safety. Lambda\nlayers are not well suited to stateful computation; instead, writing a\nsubclassed Layer is the recommend way to define layers with\nVariables."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv6FEfdRytQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "camera_coord = tf.keras.layers.Reshape((307200,1),name='camera_coord1')(depth_A)\n",
        "def camera_coord_fun(depth):\n",
        "  return depth*unscaled_cam_coord.reshape(307200,3)\n",
        "  \n",
        "camera_coord = tf.keras.layers.Lambda(camera_coord_fun,name='camera_coord2')(camera_coord)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSy_MIQD3xKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's an annoying way to get an output of all ones.  I used a layer with 1 neuron as an intermediary to avoid too many weights\n",
        "ones_layer = tf.keras.layers.Flatten(name='ones1')(depth_A)\n",
        "ones_layer = tf.keras.layers.Dense(1,use_bias=False,weights=[np.zeros([307200,1])],trainable=False,name='ones2')(ones_layer)\n",
        "ones_layer = tf.keras.layers.Dense(307200,weights=[np.zeros([1,307200]),np.ones(307200)],trainable=False,name='ones3')(ones_layer)\n",
        "ones_layer = tf.keras.layers.Reshape((307200,1),name='ones4')(ones_layer)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7N8Gat-25DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "homog_camera_coord = tf.keras.layers.concatenate([camera_coord, ones_layer],name='homog_camera_coord')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyzsE-VB8CGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # new_homog_camera_coord = tf.keras.backend.dot(homog_camera_coord, tf.keras.backend.transpose(tf.reshape(delta_pose,(4,4))))\n",
        " # new_homog_camera_coord = tf.math.divide(new_homog_camera_coord, tf.reshape(new_homog_camera_coord[:,2], (307200,1)) ) \n",
        " new_homog_camera_coord = tf.keras.layers.Dot(axes=(2,2),name='new_homog_camera_coord1')([homog_camera_coord,exp_xi]) # not sure if axes value is correct, but the output has all ones on the right side, so it's probably right\n",
        "\n",
        " new_coord_depth = tf.keras.layers.Lambda(lambda coord: coord[:,:,2],name='new_coord_depth1')(new_homog_camera_coord)\n",
        " new_coord_depth = tf.keras.layers.Reshape((307200,1),name='new_coord_depth2')(new_coord_depth)\n",
        " def new_homog_camera_coord_fun(x):\n",
        "   return tf.math.divide(x[0],x[1])\n",
        "new_homog_camera_coord = tf.keras.layers.Lambda(new_homog_camera_coord_fun,name='new_homog_camera_coord2')((new_homog_camera_coord,new_coord_depth))\n",
        "new_homog_camera_coord = tf.keras.layers.Lambda(lambda coord: coord[:,:,0:3],name='new_homog_camera_coord3')(new_homog_camera_coord)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOgMNSi2A1kH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  pixel_list = tf.keras.backend.dot(tf.reshape(new_homog_camera_coord[:,0:3],(307200,3)), tf.keras.backend.transpose(K))\n",
        "# I guess I need to create a layer corresponding to K first\n",
        "# I used a layer with 1 neuron as an intermediary to avoid too many weights\n",
        "K_layer = tf.keras.layers.Flatten(name='K1')(depth_A)\n",
        "K_layer = tf.keras.layers.Dense(1,use_bias=False,weights=[np.zeros([307200,1])],trainable=False,name='K2')(K_layer)\n",
        "K_layer = tf.keras.layers.Dense(9,weights=[np.zeros([1,9]),K.reshape(9)],trainable=False,name='K3')(K_layer)\n",
        "K_layer = tf.keras.layers.Reshape((3,3),name='K4')(K_layer)\n",
        "\n",
        "pixel_list = tf.keras.layers.Dot(axes=(2,2),name='pixel_list1')([new_homog_camera_coord,K_layer]) # not sure if axes value is correct\n",
        "pixel_list = tf.keras.layers.Lambda(lambda pix: pix[:,:,0:2],name='pixel_list2')(pixel_list)\n",
        "#pixel_list = tf.keras.layers.Reshape((1,307200,2))(pixel_list)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix7F4jKlCP00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# interp = tfa.image.interpolate_bilinear(grid=tf.reshape(image1[-1, :, :, :], (1, 480, 640,3)), query_points=tf.reshape(pixel_list[:,0:2], (-1,307200,2)))\n",
        "#grid_A = tf.keras.layers.Reshape((1,480,640,3))(input_A)\n",
        "def interp_fun(x):\n",
        "  return tfa.image.interpolate_bilinear(grid=tf.reshape(x[0],(-1,480,640,3)),query_points=tf.reshape(x[1],(-1,307200,2)))\n",
        "interp = tf.keras.layers.Lambda(interp_fun,name='interp')((input_A,pixel_list))\n",
        "new_image = tf.keras.layers.Reshape((480,640,3),name='new_image')(interp)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqFnq6biHlhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "035db923-7719-4e46-8c69-db5702f4194d"
      },
      "source": [
        "interp.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 307200, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwglz_ojD0Bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfbbd906-d557-497f-9b59-a1392c574b0e"
      },
      "source": [
        "new_image.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 480, 640, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKjsT8hgqeWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c8c5884-a3bd-466f-ae3f-2f0a33c31799"
      },
      "source": [
        "pixel_list.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 307200, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwlofGOpNQR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d90df645-8553-45e6-98bd-9a6c8ad94975"
      },
      "source": [
        "w = tf.constant([np.random.rand(480,640,3),np.random.rand(480,640,3)])\n",
        "model = tf.keras.models.Model(inputs=[input_A],outputs=[input_A])\n",
        "model.predict([w]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 480, 640, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB1nhVWANfc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c95b6ec-0f7f-4de8-bdda-055be675d6ed"
      },
      "source": [
        "w = tf.constant([np.random.rand(480,640,3),np.random.rand(480,640,3)])\n",
        "x = tf.constant([np.random.rand(480,640,1),np.random.rand(480,640,1)])\n",
        "y = tf.constant([np.random.rand(6),np.random.rand(6)])\n",
        "model = tf.keras.models.Model(inputs=[input_A,depth_A,input_xi],outputs=[interp])\n",
        "model.predict([w,x,y]).shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 307200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiMtm9F74YrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = tf.constant([np.random.rand(480,640,3)])\n",
        "x = tf.constant([np.random.rand(480,640,1)])\n",
        "y = tf.constant([np.random.rand(6)])\n",
        "model = tf.keras.models.Model(inputs=[input_A,depth_A,input_xi],outputs=[interp])\n",
        "pred = model.predict([w,x,y])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqTIOuw7unoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = tf.constant([np.zeros([480,640,3])])\n",
        "x = tf.constant([np.ones([480,640,1])])\n",
        "y = tf.constant([np.zeros(6)])\n",
        "model = tf.keras.models.Model(inputs=[input_A,depth_A,input_xi],outputs=[new_image])\n",
        "pred = model.predict([w,x,y])"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA1sb1rb1Vby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c36a732a-3702-43d4-f904-437a6ef09961"
      },
      "source": [
        "np.sum(pred)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    }
  ]
}