{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Warping for PoseNet - Freiburg, warping only (no data)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjn6862/Freiburg_dataset/blob/master/Warping_for_PoseNet_Freiburg%2C_warping_only_(no_data).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kq-rlJxzHbr",
        "colab_type": "text"
      },
      "source": [
        "**Import Statements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypG-_b90k7Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow_graphics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sguc70jY5xt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_graphics.geometry.transformation as tfg_transformation\n",
        "from tensorflow import keras\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "from datetime import datetime\n",
        "import csv\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D0xuO74GB9N",
        "colab_type": "text"
      },
      "source": [
        "**Define the input layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAQDTSVmxI7p",
        "colab_type": "text"
      },
      "source": [
        "**Create HTM from 6x1**\n",
        "\n",
        "Equations taken from DVO paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfgLVnl4GHC1",
        "colab_type": "text"
      },
      "source": [
        "**Define the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BszGQ-CEGEDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = tf.keras.layers.Input(shape=(480, 640, 3), name=\"first_image\")\n",
        "depth_A = tf.keras.layers.Input(shape=(480, 640, 1), name=\"first_depth\")\n",
        "input_B = tf.keras.layers.Input(shape=(480, 640, 3), name=\"second_image\")\n",
        "depth_B = tf.keras.layers.Input(shape=(480, 640, 1), name=\"second_depth\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2emlkaGmHuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_dim = 6\n",
        "concat = tf.keras.layers.concatenate([input_A, input_B])\n",
        "conv1 = tf.keras.layers.Conv2D(16,(7, 7), padding='same', strides=(2, 2), activation='relu')(concat)\n",
        "conv2 = tf.keras.layers.Conv2D(32, (5, 5), padding='same', strides=(2, 2), activation='relu')(conv1)\n",
        "conv3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv2)\n",
        "conv4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv3)\n",
        "conv5 = tf.keras.layers.Conv2D(256,(3, 3), padding='same', strides=(2, 2), activation='relu')(conv4)\n",
        "conv6 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv5)\n",
        "conv7 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', strides=(2, 2), activation='relu')(conv6)\n",
        "readout = tf.keras.layers.Conv2D(out_dim, (1, 1))(conv7)\n",
        "readout = 0.1*tf.keras.layers.AveragePooling2D((4,5))(readout)\n",
        "readout = tf.keras.layers.Flatten()(readout)       # first three elements correspond to the rotational velocity and the other three to the traslational velocity\n",
        "#htm = batch_mat_exp(readout)\n",
        "#image_A = tf.keras.backend.reshape(input_A,(1,480,640,3))\n",
        "#out_img = warp_image(image_A, depth_A, htm)\n",
        "#model = tf.keras.models.Model(inputs=[input_A, depth_A, input_B, depth_B], outputs=[htm])\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL-DAJ49RWwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hx, wx, h1 as the homogeneous pixel coordinates\n",
        "# This appears to match the original paper's output format\n",
        "height_coord = range(480)\n",
        "width_coord = range(640)\n",
        "hx, wx = pixel_coord = np.meshgrid(height_coord, width_coord, indexing='ij')\n",
        "hx = hx.reshape((480, 640, 1))\n",
        "wx = wx.reshape((480, 640, 1))\n",
        "h1 = np.ones(hx.shape)\n",
        "\n",
        "grid = np.concatenate((hx, wx, h1), axis=-1)\n",
        "\n",
        "# Define the camera intrinsic matrix\n",
        "#K = np.array([[525.,0.,319.5], [0., 525., 239.5], [0.,0.,1.]])  # This is how the rostopic defines it\n",
        "K = np.array([[525.,0.,239.5], [0., 525., 319.5], [0.,0.,1.]])\n",
        "\n",
        "# Define the camera coordinates of each piel up to a depth scale factor\n",
        "unscaled_cam_coord = np.empty(grid.shape)\n",
        "for i in range(480):\n",
        "      for j in range(640):\n",
        "        unscaled_cam_coord[i,j,:]= np.linalg.inv(K).dot(grid[i,j,:])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxoaCbCJO5n9",
        "colab_type": "text"
      },
      "source": [
        "**Starting here: layers to go from 6-dim vector to 4x4 HTM within model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY5fR8urnHCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_xi = tf.keras.layers.Input(shape=(6), name=\"xi\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNB8EBR38Vuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 3x3 matrix omega_x from xi=[omega nu]\n",
        "omega_x_weights = np.zeros([6,9])\n",
        "omega_x_weights[0,5]=-1\n",
        "omega_x_weights[0,7]=1\n",
        "omega_x_weights[1,2]=1\n",
        "omega_x_weights[1,6]=-1\n",
        "omega_x_weights[2,1]=-1\n",
        "omega_x_weights[2,3]=1\n",
        "\n",
        "omega_x = tf.keras.layers.Dense(9,use_bias=False,weights=[omega_x_weights],trainable=False)(input_xi)\n",
        "omega_x = tf.keras.layers.Reshape((3,3))(omega_x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBtHpM4p9lUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create 3-dimensional vector nu from xi=[omega nu]\n",
        "nu_weights = np.zeros([6,3])\n",
        "nu_weights[3,0]=1\n",
        "nu_weights[4,1]=1\n",
        "nu_weights[5,2]=1\n",
        "\n",
        "nu = tf.keras.layers.Dense(3,use_bias=False,weights=[nu_weights],trainable=False)(input_xi)\n",
        "#nu = tf.keras.layers.Reshape((3,1))(nu)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvTvMfTe-UVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get ||omega|| from xi\n",
        "def om_norm_fun(xi):\n",
        "  return tf.norm(xi[0,0:3])\n",
        "om_norm = tf.keras.layers.Lambda(om_norm_fun)(input_xi)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noJLF97wFBqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get omega_x**2\n",
        "omega_x_squared = tf.keras.layers.Dot(axes=(1,2))([omega_x,omega_x])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAE4gzHl_7Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get terms for exp(omega_x) and V\n",
        "# exp(omega_x) = I + term1 + term2 in (2.21)\n",
        "def term1_fun(x):\n",
        "  return tf.sin(x[1])/x[1]*x[0]\n",
        "term1 = tf.keras.layers.Lambda(term1_fun)((omega_x,om_norm))\n",
        "\n",
        "def term2_fun(x):\n",
        "  return (1-tf.cos(x[1]))/x[1]**2*x[0]\n",
        "term2 = tf.keras.layers.Lambda(term2_fun)((omega_x_squared,om_norm))\n",
        "\n",
        "# V = I + term3 + term4 in (2.22)\n",
        "def term3_fun(x):\n",
        "  return (1-tf.cos(x[1]))/x[1]**2*x[0]\n",
        "term3 = tf.keras.layers.Lambda(term3_fun)((omega_x,om_norm))\n",
        "\n",
        "def term4_fun(x):\n",
        "  return (x[1]-tf.sin(x[1]))/x[1]**3*x[0]\n",
        "term4 = tf.keras.layers.Lambda(term4_fun)((omega_x_squared,om_norm))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJgxKz2TF2rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get exp(omega_x)\n",
        "# exp_om_x = I + term1 + term2\n",
        "exp_om_x = tf.keras.layers.add([term1,term2])\n",
        "# still need to add I.  There might be a more elegant way, but I'm going to do \n",
        "# this by using a Dense layer and specifying the weights\n",
        "exp_om_x = tf.keras.layers.Flatten()(exp_om_x)\n",
        "# use identity for weights to keep the same, then use np.array([1,0,0,0,1,0,0,0,1]) to add identity matrix to exp_om_x\n",
        "exp_om_x = tf.keras.layers.Dense(9,weights=[np.eye(9),np.array([1,0,0,0,1,0,0,0,1])],trainable=False)(exp_om_x)\n",
        "exp_om_x = tf.keras.layers.Reshape((3,3))(exp_om_x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEaKoGxhJEwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get V and V*nu\n",
        "# V = I + term3 + term4\n",
        "V = tf.keras.layers.add([term3,term4])\n",
        "# still need to add I.  There might be a more elegant way, but I'm going to do \n",
        "# this by using a Dense layer and specifying the weights\n",
        "V = tf.keras.layers.Flatten()(V)\n",
        "# use identity for weights to keep the same, then use np.array([1,0,0,0,1,0,0,0,1]) to add identity matrix to exp_om_x\n",
        "V = tf.keras.layers.Dense(9,weights=[np.eye(9),np.array([1,0,0,0,1,0,0,0,1])],trainable=False)(V) \n",
        "V = tf.keras.layers.Reshape((3,3))(V)\n",
        "# get V*nu\n",
        "V_nu = tf.keras.layers.Dot(axes=(2,1))([V,nu])\n",
        "V_nu = tf.keras.layers.Reshape((3,1))(V_nu)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p79xUmZ7MsXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get exp_xi by concatenating exp_om_x and V_nu, then concatenate a bottom row of [0,0,0,1]\n",
        "exp_xi = tf.keras.layers.concatenate([exp_om_x,V_nu])\n",
        "# this is a silly way to get a bottom row of [0,0,0,1], but it works\n",
        "bottom_row = tf.keras.layers.Dense(4,weights=[np.zeros([6,4]),np.array([0,0,0,1])],trainable=False)(input_xi)\n",
        "bottom_row = tf.keras.layers.Reshape((1,4))(bottom_row)\n",
        "\n",
        "exp_xi = tf.keras.layers.concatenate([exp_xi,bottom_row],axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG79qnjH8qm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7931a6d0-8877-4ab8-d7a4-fbb847117c09"
      },
      "source": [
        "xi = tf.constant([[0.3,0.2,0.6,0.8,0.5,0.7]])\n",
        "model = tf.keras.models.Model(inputs=[input_xi],outputs=[exp_xi])\n",
        "model.predict(xi)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.80803442, -0.52339177,  0.27044671,  0.69654235],\n",
              "        [ 0.58098144,  0.78403873, -0.21850363,  0.61445211],\n",
              "        [-0.09767769,  0.33368298,  0.93761119,  0.71357812],\n",
              "        [ 0.        ,  0.        ,  0.        ,  1.        ]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27JWhZNvQeQG",
        "colab_type": "text"
      },
      "source": [
        "**Here starts the attempts to warp from input_A, depth_A, and exp_xi**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBBK7_IrQdEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hx, wx, h1 as the homogeneous pixel coordinates\n",
        "# This appears to match the original paper's output format\n",
        "height_coord = range(480)\n",
        "width_coord = range(640)\n",
        "hx, wx = pixel_coord = np.meshgrid(height_coord, width_coord, indexing='ij')\n",
        "hx = hx.reshape((480, 640, 1))\n",
        "wx = wx.reshape((480, 640, 1))\n",
        "h1 = np.ones(hx.shape)\n",
        "\n",
        "grid = np.concatenate((hx, wx, h1), axis=-1)\n",
        "\n",
        "# Define the camera intrinsic matrix\n",
        "#K = np.array([[525.,0.,319.5], [0., 525., 239.5], [0.,0.,1.]])  # This is how the rostopic defines it\n",
        "K = np.array([[525.,0.,239.5], [0., 525., 319.5], [0.,0.,1.]])\n",
        "\n",
        "# Define the camera coordinates of each piel up to a depth scale factor\n",
        "unscaled_cam_coord = np.empty(grid.shape)\n",
        "for i in range(480):\n",
        "      for j in range(640):\n",
        "        unscaled_cam_coord[i,j,:]= np.linalg.inv(K).dot(grid[i,j,:])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH3wr94Piyem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def warp_image(tensor):\n",
        "  image1 = tensor[0]\n",
        "  depth1 = tensor[1]\n",
        "  delta_pose = tensor[2]\n",
        "  # This function takes an image and depth map and predicts the view after a transformation by delta_pose\n",
        "  # What would image1 taken at the location after delta_pose look like? Should match image2\n",
        "  new_image = tf.keras.backend.ones_like(image1)\n",
        "  camera_coord = tf.reshape(depth1[-1,:,:],(307200,1))*unscaled_cam_coord.reshape(307200, 3)\n",
        "  homog_camera_coord = tf.keras.backend.concatenate((camera_coord, tf.keras.backend.ones((307200,1),dtype=tf.float64)) )\n",
        "  pixel_list = tf.keras.backend.zeros((307200, 2))\n",
        "  new_homog_camera_coord = tf.keras.backend.dot(homog_camera_coord, tf.keras.backend.transpose(tf.reshape(delta_pose,(4,4))))\n",
        "  new_homog_camera_coord = tf.math.divide(new_homog_camera_coord, tf.reshape(new_homog_camera_coord[:,2], (307200,1)) ) \n",
        "  pixel_list = tf.keras.backend.dot(tf.reshape(new_homog_camera_coord[:,0:3],(307200,3)), tf.keras.backend.transpose(K))\n",
        "  interp = tfa.image.interpolate_bilinear(grid=tf.reshape(image1[-1, :, :, :], (1, 480, 640,3)), query_points=tf.reshape(pixel_list[:,0:2], (-1,307200,2)))\n",
        "  new_image = tf.reshape(interp, (-1,480, 640, 3))\n",
        "  print('new_image=',new_image)\n",
        "  print('camer_coord=',camera_coord)\n",
        "  print('homog_camera_coord=',homog_camera_coord)\n",
        "  print('pixel_list=',pixel_list)\n",
        "  print('new_homog_camera_coord=',new_homog_camera_coord)\n",
        "  print('interp=',interp)\n",
        "  print('new_image=',new_image)\n",
        "  return new_image"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2VvCuyNkkDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "fd85d543-9b70-45b4-e7ac-090221d46e4b"
      },
      "source": [
        "out = tf.keras.layers.Lambda(warp_image, name='warp_layer')([input_A, depth_A, exp_xi])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new_image= Tensor(\"warp_layer_29/Reshape_6:0\", shape=(1, 480, 640, 3), dtype=float64)\n",
            "camer_coord= Tensor(\"warp_layer_29/mul:0\", shape=(307200, 3), dtype=float64)\n",
            "homog_camera_coord= Tensor(\"warp_layer_29/concat:0\", shape=(307200, 4), dtype=float64)\n",
            "pixel_list= Tensor(\"warp_layer_29/MatMul_1:0\", shape=(307200, 3), dtype=float64)\n",
            "new_homog_camera_coord= Tensor(\"warp_layer_29/truediv:0\", shape=(307200, 4), dtype=float64)\n",
            "interp= Tensor(\"warp_layer_29/PartitionedCall:0\", shape=(1, 307200, 3), dtype=float64)\n",
            "new_image= Tensor(\"warp_layer_29/Reshape_6:0\", shape=(1, 480, 640, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-1a7a4bbc54c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warp_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_xi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    921\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_check_variables\u001b[0;34m(self, created_variables, accessed_variables)\u001b[0m\n\u001b[1;32m    914\u001b[0m           Variables.'''\n\u001b[1;32m    915\u001b[0m       ).format(name=self.name, variable_str=variable_str)\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     untracked_used_vars = [\n",
            "\u001b[0;31mValueError\u001b[0m: \nThe following Variables were created within a Lambda layer (warp_layer)\nbut are not tracked by said layer:\n  <tf.Variable 'warp_layer_29/Variable:0' shape=(307200, 1) dtype=float64>\n  <tf.Variable 'warp_layer_29/Variable:0' shape=(307200, 2) dtype=float64>\nThe layer cannot safely ensure proper Variable reuse across multiple\ncalls, and consquently this behavior is disallowed for safety. Lambda\nlayers are not well suited to stateful computation; instead, writing a\nsubclassed Layer is the recommend way to define layers with\nVariables."
          ]
        }
      ]
    }
  ]
}